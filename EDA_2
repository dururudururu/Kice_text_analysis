################## Library Settings ############
library(rJava)
library(KoNLP)
library(tm)
library(ggplot2)
library(wordcloud)
library(wordcloud2)
library(stringr)
KoNLP::useNIADic()
################################################


## 0.File load to 'list' ##
setwd("C:/data/Kice_text")
file_list <- list.files("C:/data/Kice_text")
text_list <- lapply(file_list, readLines)


## 1.개별 파일의 전처리 ##
# 1.1.면담자 질문, 구두점, 특수문자, 학교이름 등 제거하기
interv1 <- readLines("interview1.txt")
interviewer <- grep("면담자", interv1)
interv1 <- interv1[-interviewer]

rawtex <- c(interv1, interv2)
rawtex <- gsub("것", "", rawtex)
rawtex <- gsub("저희", "", rawtex)
rawtex <- gsub("모둠", "", rawtex)
rawtex <- gsub("한", "", rawtex)
rawtex <- gsub("하", "", rawtex)
rawtex <- gsub("\\d+","",rawtex)
rawtex <- gsub("\\.","",rawtex)
rawtex <- gsub("학생","",rawtex)
rawtex <- gsub("웃음","",rawtex)
rawtex <- gsub("-","",rawtex)
rawtex <- gsub("\\:","",rawtex)

# 1.2.SimplePos9으로 체언, 용언, 수식언, 외국어 추출
# 1.3.단어 벡터 보면서 클리닝, 딕셔너리 추가, 단어 형태 통일 
open1 <- readLines("open1.txt")
open2 <- readLines("open2.txt")





#txt1 <- KoNLP::extractNoun(rawtex)
txt1 <- KoNLP::SimplePos09(rawtex)
txt1 <- unlist(txt1)
txt1 <- stringr::str_match(txt1, '([가-힣]+)/[FNPM]')
## 9품사 or 22품사분류에서 잡아내는 것 짜는 중이었음.
## 단어사전에 추가해야되고 잘라야 되는 단어가 많음.
## if txt1[,1] /= P, M & if length(txt[,2]) < 2, then remove.

wordbag <- Filter(function(x){nchar(x)>=2}, txt1[,2])

wordcount <- table(wordbag)
wordcount <- wordcount[wordcount>1]

pal <- brewer.pal(9, "Set1")
wordcloud(names(wordcount), freq=wordcount, scale=c(3, 1),
          random.order = F, rot.per=.25, colors=pal)

#wordcloud2(wordcount, color='random-dark', minRotation = -pi/2, maxRotation = -pi/2)
